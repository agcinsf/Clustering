{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "K-Nearest Neighbors"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This code injests pictures of written numbers and classifies them into their actual number."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "directory = 'C:/Users/Ac/Google Drive/Kaggle/digits/'\n",
      "train = 'train.csv'\n",
      "test = 'test.csv'\n",
      "\n",
      "\n",
      "def ReadInFile(FileLoc,FileName, Filetype):\n",
      "    f = open(directory + FileName)\n",
      "    X = []\n",
      "    y = []\n",
      "    \n",
      "    i = 1\n",
      "    for line in f:\n",
      "        if Filetype == 'train':\n",
      "            if i>1:\n",
      "                X.append(map(float,line[2:].strip().split(',')))\n",
      "                y.append(int(line[0]))\n",
      "            i+=1\n",
      "        else:\n",
      "            if i>1:\n",
      "                X.append(line.strip().split(','))\n",
      "            i+=1\n",
      "    return X,y\n",
      "\n",
      "\n",
      "def writeOut(location, name,obj):\n",
      "    numpy.savetxt(location + name, obj, delimiter=',')\n",
      "\n",
      "def main():\n",
      "    from sklearn.neighbors import KNeighborsClassifier\n",
      "    from sklearn.svm import LinearSVC\n",
      "    from sklearn.decomposition import PCA \n",
      "    from sklearn.externals import joblib\n",
      "    from sklearn.ensemble import RandomForestClassifier\n",
      "    from sklearn.ensemble import ExtraTreesClassifier\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "    from sklearn import preprocessing\n",
      "    from sklearn import cross_validation\n",
      "    import csv\n",
      "    \n",
      "    X_train = []\n",
      "    y_train = []\n",
      "    X_test = []\n",
      "    y_test = []\n",
      "    Xtrain_PCA = []\n",
      "    Xtest_PCA = []\n",
      "    pred = []\n",
      "    \n",
      "    X, y = ReadInFile(directory,train,'train') \n",
      "    scaler = preprocessing.StandardScaler().fit(X)\n",
      "    \n",
      "    \n",
      "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20,random_state=0)\n",
      "    X_train = scaler.transform(X_train)\n",
      "    X_test = scaler.transform(X_test)\n",
      "\n",
      "    Test,testy = ReadInFile(directory,test,'test') \n",
      "    \n",
      "    \n",
      "    #Reduce the feature space of the X_train matrix\n",
      "    #pca = PCA(n_components=600)\n",
      "    #Xtrain_PCA = pca.fit_transform(X_train)\n",
      "    #Xtest_PCA = pca.fit_transform(X_test)\n",
      "    \n",
      "    #print(pca.explained_variance_ratio_) \n",
      "    \n",
      "    \n",
      "    neigh = ExtraTreesClassifier(n_estimators=20, criterion='gini', n_jobs=1).fit(X_train,y_train)\n",
      "    #scores = cross_validation.cross_val_score(neigh, X_test, y_test, cv=5)\n",
      "    #print scores.mean(), scores.std()/2\n",
      "    \n",
      "    probs = neigh.predict_proba(X_test)\n",
      "    #pred = neigh.predict(Test)\n",
      "    \n",
      "    writeOut('C:/Users/Ac/Google Drive/Kaggle/digits/','ys.csv',y_test)\n",
      "    writeOut('C:/Users/Ac/Google Drive/Kaggle/digits/','probs.csv',probs)\n",
      "    #writeOut('C:/Users/Aclark/Google Drive/Kaggle/digits/', pred)\n",
      "    \n",
      "if __name__ == '__main__':\n",
      "    %time main()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 268.33 s, sys: 0.00 s, total: 268.33 s\n",
        "Wall time: 268.22 s\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "directory = 'C:/Users/Aclark/Google Drive/Kaggle/digits/'\n",
      "train = 'train.csv'\n",
      "test = 'test.csv'\n",
      "\n",
      "\n",
      "def ReadInFile(FileLoc,FileName, Filetype):\n",
      "    f = open(directory + FileName)\n",
      "    X = []\n",
      "    y = []\n",
      "    \n",
      "    i = 1\n",
      "    for line in f:\n",
      "        if Filetype == 'train':\n",
      "            if i>1:\n",
      "                X.append(map(float,line[2:].strip().split(',')))\n",
      "                y.append(int(line[0]))\n",
      "            i+=1\n",
      "        else:\n",
      "            if i>1:\n",
      "                X.append(line.strip().split(','))\n",
      "            i+=1\n",
      "    return X,y\n",
      "\n",
      "\n",
      "def writeOut(location, name,obj):\n",
      "    numpy.savetxt(location + name, obj, delimiter=',')\n",
      "\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.cross_validation import train_test_split\n",
      "    \n",
      "X_train = []\n",
      "y_train = []\n",
      "X_test = []\n",
      "y_test = []\n",
      "Xtrain_PCA = []\n",
      "Xtest_PCA = []\n",
      "pred = []\n",
      "   \n",
      "X, y = ReadInFile(directory,train,'train') \n",
      "   \n",
      "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20,random_state=0)\n",
      "\n",
      "Test,testy = ReadInFile(directory,test,'test') \n",
      "\n",
      "#Run\n",
      "classifier = SGDClassifier(loss='modified_huber', n_iter=8, shuffle=True, class_weight='auto', penalty='elasticnet')\n",
      "classifier.fit(X_train,y_train)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "SGDClassifier(alpha=0.0001, class_weight='auto', epsilon=0.1, eta0=0.0,\n",
        "       fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',\n",
        "       loss='modified_huber', n_iter=8, n_jobs=1, penalty='elasticnet',\n",
        "       power_t=0.5, random_state=None, rho=None, shuffle=True, verbose=0,\n",
        "       warm_start=False)"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "SGDClassifier(alpha=0.0001, class_weight='auto', epsilon=0.1, eta0=0.0,\n",
        "       fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',\n",
        "       loss='modified_huber', n_iter=8, n_jobs=1, penalty='elasticnet',\n",
        "       power_t=0.5, random_state=None, rho=None, shuffle=True, verbose=0,\n",
        "       warm_start=False)"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print classifier.score(X_test,y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.892738095238\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-13-8d7c62ddbd2a>, line 1)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-13-8d7c62ddbd2a>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    A[1][1].1\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}